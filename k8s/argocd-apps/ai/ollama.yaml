apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: ollama
  namespace: argocd
  finalizers:
    - resources-finalizer.argocd.argoproj.io
spec:
  project: ai

  source:
    chart: ollama
    repoURL: https://helm.otwld.com/
    targetRevision: 1.37.0
    helm:
      releaseName: ollama
      values: |
        # Persistent storage for models
        persistentVolume:
          enabled: true
          size: 50Gi
          storageClass: proxmox-zfs-nvme 
        
        # Resource limits
        # resources:
        #   requests:
        #     memory: 4Gi
        #     cpu: 2
        #   limits:
        #     memory: 8Gi
        #     cpu: 4
        
        # Ollama configuration
        ollama:
           GPU support (uncomment if using GPU)
           gpu:
             enabled: true
             type: nvidia
             number: 1
        
          # Models to pull at startup
          models:
            pull:
              - llama3.2:3b
              - nomic-embed-text
        
          # Optional: Custom models with specific parameters
          # models:
          #   create:
          #     - name: llama3.1-ctx16384
          #       template: |
          #         FROM llama3.1:8b
          #         PARAMETER num_ctx 16384
          #   run:
          #     - llama3.1-ctx16384
        
          # Environment variables
          extraEnv:
            - name: OLLAMA_KEEP_ALIVE
              value: "24h"
            - name: OLLAMA_HOST
              value: "0.0.0.0"
        
        # Service configuration
        service:
          type: ClusterIP
          port: 11434
        
        # Ingress (optional)
        ingress:
          enabled: false
          # enabled: true
          # className: nginx
          # annotations:
          #   cert-manager.io/cluster-issuer: letsencrypt-prod
          # hosts:
          #   - host: ollama.yourdomain.com
          #     paths:
          #       - path: /
          #         pathType: Prefix
          # tls:
          #   - secretName: ollama-tls
          #     hosts:
          #       - ollama.yourdomain.com

  destination:
    server: https://kubernetes.default.svc
    namespace: ai

  syncPolicy:
    automated:
      prune: true
      selfHeal: true